import os
import json
import pickle
import numpy as np
import tensorflow as tf
import mlflow
from tqdm import tqdm

# =============================================================================
# 1. SETUP CREDENTIALS (MINIO & MLFLOW)
# =============================================================================
# ƒê·∫£m b·∫£o c√°c th√¥ng s·ªë n√†y kh·ªõp v·ªõi docker-compose c·ªßa b·∫°n
os.environ["AWS_ACCESS_KEY_ID"] = "minioadmin"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minioadmin"
os.environ["AWS_DEFAULT_REGION"] = "us-east-1"
os.environ["MLFLOW_S3_ENDPOINT_URL"] = os.getenv("MINIO_ENDPOINT", "http://minio:9000")
os.environ["MLFLOW_TRACKING_URI"] = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")

# =============================================================================
# 2. IMPORTS & CONFIG
# =============================================================================
# --- IMPORT MODEL CLASS ---
# C·ªë g·∫Øng import class SasRec. File model.py ph·∫£i n·∫±m c√πng th∆∞ m·ª•c ho·∫∑c trong PYTHONPATH
try:
    from model import SasRec
except ImportError:
    try:
        from src.ai_core.model import SasRec
    except ImportError:
        print("‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y class 'SasRec'.")
        print("üëâ H√£y ƒë·∫£m b·∫£o file 'model.py' n·∫±m c√πng th∆∞ m·ª•c v·ªõi script n√†y.")
        import sys; sys.exit(1)

# C·∫•u h√¨nh chung
EXPERIMENT_NAME = "sasrec_original_config_kiet"
DOWNLOAD_DIR = "./downloaded_artifacts"  # Th∆∞ m·ª•c t·∫°m ƒë·ªÉ l∆∞u file t·∫£i v·ªÅ
MAX_LEN = 50       # ƒê·ªô d√†i chu·ªói (ph·∫£i kh·ªõp v·ªõi l√∫c train)
NUM_NEG_TEST = 99  # Sampled Metrics: 1 Positive vs 99 Negatives
SEED = 42

# Thi·∫øt l·∫≠p Seed
np.random.seed(SEED)
tf.random.set_seed(SEED)

# =============================================================================
# 3. H√ÄM T·∫¢I ARTIFACTS T·ª™ MLFLOW
# =============================================================================
def fetch_artifacts_and_get_run_id():
    print(f"\nüåç ƒêang k·∫øt n·ªëi MLflow t·∫°i: {os.environ['MLFLOW_TRACKING_URI']}")
    mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
    
    # 1. T√¨m Experiment
    exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    if exp is None:
        raise ValueError(f"‚ùå Kh√¥ng t√¨m th·∫•y Experiment t√™n: '{EXPERIMENT_NAME}'")
    
    # 2. T√¨m Run m·ªõi nh·∫•t (ƒë√£ ho√†n th√†nh)
    print("üîç ƒêang t√¨m Run m·ªõi nh·∫•t c√≥ tr·∫°ng th√°i 'FINISHED'...")
    runs = mlflow.search_runs(
        experiment_ids=[exp.experiment_id],
        filter_string="status = 'FINISHED'",
        order_by=["start_time DESC"],
        max_results=1
    )
    
    if runs.empty:
        raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y Run n√†o ƒë√£ ho√†n th√†nh (FINISHED).")
    
    last_run_id = runs.iloc[0].run_id
    print(f"‚úÖ ƒê√£ t√¨m th·∫•y Run ID: {last_run_id}")

    # 3. T·∫°o th∆∞ m·ª•c t·∫°m
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)

    # 4. T·∫£i Model & Data
    print("üì• ƒêang t·∫£i Model v√† Test Set t·ª´ MinIO...")
    
    # L∆∞u √Ω: artifact_path ph·∫£i kh·ªõp v·ªõi l√∫c b·∫°n log trong code training
    # M·∫∑c ƒë·ªãnh l√†: 'model_keras' v√† 'data_splits'
    model_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="model_keras/sasrec_v1.keras", dst_path=DOWNLOAD_DIR)
    test_set_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="data_splits/test_set.pkl", dst_path=DOWNLOAD_DIR)
    
    # Th·ª≠ t·∫£i item_map (n·∫øu c√≥)
    try:
        map_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="metadata/item_map.json", dst_path=DOWNLOAD_DIR)
    except:
        print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y 'item_map.json' tr√™n Server. S·∫Ω t·ª± ƒë·ªông suy lu·∫≠n Vocab Size.")
        map_path = None

    return last_run_id, model_path, test_set_path, map_path

# =============================================================================
# 4. H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU (PADDING)
# =============================================================================
def pad_sequence(seq, max_len):
    seq = list(seq)
    pad_len = max_len - len(seq)
    # Post-padding: Th√™m s·ªë 0 v√†o sau ƒëu√¥i
    padded_seq = seq + [0] * pad_len
    # Mask: True cho v·ªã tr√≠ c√≥ gi√° tr·ªã, False cho padding
    mask = [True] * len(seq) + [False] * pad_len
    return np.array(padded_seq, dtype=np.int32), np.array(mask, dtype=bool)

# =============================================================================
# 5. MAIN EVALUATION LOOP
# =============================================================================
def main():
    print("\n" + "="*60)
    print("üöÄ B·∫ÆT ƒê·∫¶U QU√Å TR√åNH ƒê√ÅNH GI√Å (OFFLINE EVALUATION)")
    print("="*60)

    # --- B∆Ø·ªöC 1: T·∫¢I DATA ---
    try:
        run_id, model_path, test_set_path, item_map_path = fetch_artifacts_and_get_run_id()
    except Exception as e:
        print(f"‚ùå L·ªói t·∫£i Artifacts: {e}")
        return

    # --- B∆Ø·ªöC 2: LOAD DATA & MODEL ---
    print(f"\nüìÇ ƒêang ƒë·ªçc d·ªØ li·ªáu...")
    with open(test_set_path, "rb") as f:
        test_set = pickle.load(f)
    
    # X√°c ƒë·ªãnh Vocab Size
    if item_map_path and os.path.exists(item_map_path):
        with open(item_map_path, "r") as f:
            item_map = json.load(f)
        vocab_size = len(item_map)
    else:
        # Fallback: Qu√©t to√†n b·ªô test set ƒë·ªÉ t√¨m max ID
        all_items = [x for s in test_set for x in s['input_items']]
        vocab_size = max(all_items)
        print(f"‚ö†Ô∏è ƒê√£ suy lu·∫≠n Vocab Size t·ª´ d·ªØ li·ªáu test: {vocab_size}")

    print(f"üèóÔ∏è ƒêang load Model t·ª´: {model_path}")
    try:
        # Load model nguy√™n kh·ªëi, mapping class SasRec
        model = tf.keras.models.load_model(model_path, custom_objects={'SasRec': SasRec}, compile=False)
        print("‚úÖ Model loaded th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói load model Keras: {e}")
        return

    # --- B∆Ø·ªöC 3: CH·∫†Y ƒê√ÅNH GI√Å ---
    hits_10 = 0
    ndcgs_10 = 0
    
    # Cache Embedding Matrix ƒë·ªÉ tƒÉng t·ªëc
    item_weights = model.item_embedding.embeddings 

    print(f"\nüèÅ ƒêang ch·∫°y Test tr√™n {len(test_set)} users (Sampled 1 vs {NUM_NEG_TEST} Negatives)...")
    
    for sample in tqdm(test_set, desc="Evaluating"):
        seq_items = sample["input_items"]
        seq_cats = sample["input_cats"]
        target_item = sample["label"]

        # A. Negative Sampling (Ch·ªçn 99 item ng·∫´u nhi√™n user ch∆∞a xem)
        seen_items = set(seq_items)
        seen_items.add(target_item)
        
        # List candidate g·ªìm 1 Positive ƒë·∫ßu ti√™n + 99 Negatives
        test_items = [target_item]
        while len(test_items) < NUM_NEG_TEST + 1:
            neg = np.random.randint(1, vocab_size + 1)
            if neg not in seen_items:
                test_items.append(neg)

        # B. Ti·ªÅn x·ª≠ l√Ω Input (C·∫Øt & Padding)
        # Ch·ªâ l·∫•y MAX_LEN item cu·ªëi c√πng
        seq_items_sliced = list(seq_items)[-MAX_LEN:]
        seq_cats_sliced = list(seq_cats)[-MAX_LEN:]
        valid_len = len(seq_items_sliced)

        in_items, mask = pad_sequence(seq_items_sliced, MAX_LEN)
        in_cats, _ = pad_sequence(seq_cats_sliced, MAX_LEN)

        # Th√™m Batch Dimension [1, MAX_LEN]
        in_items = np.expand_dims(in_items, axis=0)
        in_cats = np.expand_dims(in_cats, axis=0)
        mask = np.expand_dims(mask, axis=0)

        # C. Inference (D·ª± ƒëo√°n)
        outputs = model(
            {"item_ids": in_items, "category_ids": in_cats, "padding_mask": mask},
            training=False
        )
        
        # L·∫•y vector ƒë·∫°i di·ªán User t·∫°i th·ªùi ƒëi·ªÉm cu·ªëi c√πng (kh√¥ng l·∫•y padding)
        # Sequence Embedding shape: [1, MAX_LEN, Embed_Dim]
        seq_emb = outputs["item_sequence_embedding"][0]
        user_emb = seq_emb[valid_len - 1] 

        # D. Ranking
        # L·∫•y vector c·ªßa 100 item candidates
        test_items_idx = tf.constant(test_items, dtype=tf.int32)
        test_item_embs = tf.gather(item_weights, test_items_idx)

        # T√≠nh Dot Product: (100, D) . (D, 1) -> (100,)
        scores = tf.matmul(test_item_embs, tf.expand_dims(user_emb, -1))
        scores = tf.squeeze(scores).numpy()

        # Item ƒë·∫ßu ti√™n (index 0) l√† Ground Truth
        # Rank = S·ªë l∆∞·ª£ng item c√≥ ƒëi·ªÉm cao h∆°n Ground Truth
        rank = np.sum(scores > scores[0])

        # E. T√≠nh Metrics
        if rank < 10:
            hits_10 += 1
            ndcgs_10 += 1.0 / np.log2(rank + 2)

    # --- B∆Ø·ªöC 4: T·ªîNG H·ª¢P K·∫æT QU·∫¢ ---
    hr_10 = hits_10 / len(test_set)
    ndcg_10 = ndcgs_10 / len(test_set)

    print("\n" + "=" * 50)
    print(f"üèÜ K·∫æT QU·∫¢ ƒê√ÅNH GI√Å (Run ID: {run_id})")
    print("=" * 50)
    print(f"üéØ Hit Rate @10 : {hr_10:.4f}")
    print(f"‚≠ê NDCG @10     : {ndcg_10:.4f}")
    print("=" * 50)

    # --- B∆Ø·ªöC 5: LOG K·∫æT QU·∫¢ NG∆Ø·ª¢C V√ÄO MLFLOW ---
    print(f"\nüìù ƒêang ghi metrics v√†o MLflow Run: {run_id}...")
    try:
        # S·ª≠ d·ª•ng ƒë√∫ng Run ID ƒë√£ t·∫£i v·ªÅ l√∫c n√£y ƒë·ªÉ ghi ƒë√® metrics
        with mlflow.start_run(run_id=run_id):
            mlflow.log_metrics({
                "test_hit_rate_10": hr_10,
                "test_ndcg_10": ndcg_10
            })
        print("‚úÖ Th√†nh c√¥ng! B·∫°n c√≥ th·ªÉ ki·ªÉm tra tr√™n MLflow UI.")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi log metrics v√†o MLflow: {e}")

if __name__ == "__main__":
    main()