import os
import json
import pickle
import numpy as np
import tensorflow as tf
import mlflow
import psycopg2
from collections import Counter
from datetime import datetime
from tqdm import tqdm

# =============================================================================
# 1. SETUP & CONFIG
# =============================================================================
os.environ["AWS_ACCESS_KEY_ID"] = "minioadmin"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minioadmin"
os.environ["AWS_DEFAULT_REGION"] = "us-east-1"
os.environ["MLFLOW_S3_ENDPOINT_URL"] = os.getenv("MINIO_ENDPOINT", "http://minio:9000")
os.environ["MLFLOW_TRACKING_URI"] = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")

DB_CONF = {
    "host": "timescaledb", 
    "port": "5432",
    "user": "postgres",
    "password": "password",
    "dbname": "ecommerce_logs"
}

EXPERIMENT_NAME = "sasrec_original_config_kiet"
DOWNLOAD_DIR = "./downloaded_artifacts"
MAX_LEN = 50
NUM_NEG_TEST = 99
SEED = 42

np.random.seed(SEED)
tf.random.set_seed(SEED)

# =============================================================================
# 2. MODEL & UTILS
# =============================================================================
try:
    from model import SasRec
except ImportError:
    try:
        from src.ai_core.model import SasRec
    except ImportError:
        print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y class 'SasRec'.")
        import sys; sys.exit(1)

def fetch_artifacts_and_get_run_id():
    # (Giá»¯ nguyÃªn code táº£i artifact nhÆ° cÃ¡c bÃ i trÆ°á»›c)
    print(f"\nğŸŒ Äang káº¿t ná»‘i MLflow...")
    mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
    exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    if not exp: raise ValueError("Experiment not found")
    
    runs = mlflow.search_runs(experiment_ids=[exp.experiment_id], filter_string="status = 'FINISHED'", order_by=["start_time DESC"], max_results=1)
    if runs.empty: raise ValueError("No run found")
    
    last_run_id = runs.iloc[0].run_id
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    
    model_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="model_keras/sasrec_v1.keras", dst_path=DOWNLOAD_DIR)
    test_set_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="data_splits/test_set.pkl", dst_path=DOWNLOAD_DIR)
    try: map_path = mlflow.artifacts.download_artifacts(run_id=last_run_id, artifact_path="metadata/item_map.json", dst_path=DOWNLOAD_DIR)
    except: map_path = None
    
    return last_run_id, model_path, test_set_path, map_path

def pad_sequence(seq, max_len):
    seq = list(seq)
    pad_len = max_len - len(seq)
    padded_seq = seq + [0] * pad_len
    mask = [True] * len(seq) + [False] * pad_len
    return np.array(padded_seq, dtype=np.int32), np.array(mask, dtype=bool)

def save_benchmark_to_db(results, run_id):
    """LÆ°u káº¿t quáº£ so sÃ¡nh 3 thuáº­t toÃ¡n vÃ o DB"""
    print(f"\nğŸ—„ï¸ Äang lÆ°u Benchmark vÃ o Database...")
    now = datetime.now()
    
    # Payload JSON chá»©a káº¿t quáº£ so sÃ¡nh
    metrics_payload = {
        "evaluated_at": now.isoformat(),
        "mlflow_run_id": run_id,
        "valid_samples": results["count"],
        
        # 1. Random
        "random_hr_10": round(results["Random"]["hr"], 4),
        "random_ndcg_10": round(results["Random"]["ndcg"], 4),
        
        # 2. Most Popular
        "pop_hr_10": round(results["MostPopular"]["hr"], 4),
        "pop_ndcg_10": round(results["MostPopular"]["ndcg"], 4),
        
        # 3. SasRec (Main)
        "sasrec_hr_10": round(results["SasRec"]["hr"], 4),
        "sasrec_ndcg_10": round(results["SasRec"]["ndcg"], 4),
        
        # 4. Fields chuáº©n Ä‘á»ƒ hiá»‡n trÃªn Dashboard cÅ© (dÃ¹ng SasRec lÃ m Ä‘áº¡i diá»‡n)
        "hit_rate_10": round(results["SasRec"]["hr"], 4),
        "ndcg_10": round(results["SasRec"]["ndcg"], 4)
    }

    try:
        conn = psycopg2.connect(**DB_CONF)
        cur = conn.cursor()
        cur.execute("""
            UPDATE model_registry 
            SET metrics = %s, status = 'EVALUATED'
            WHERE model_id = 'sasrec-video-games' OR model_path LIKE %s
        """, (json.dumps(metrics_payload), f"%{run_id}%"))
        conn.commit()
        print(f"âœ… [DB] ÄÃ£ lÆ°u báº£ng so sÃ¡nh Benchmark vÃ o DB.")
    except Exception as e:
        print(f"âŒ [DB] Lá»—i: {e}")
    finally:
        if 'conn' in locals() and conn: conn.close()

# =============================================================================
# 3. LOGIC TÃNH TOÃN BASELINE
# =============================================================================
def calculate_popularity_scores(test_set):
    """TÃ­nh Ä‘á»™ phá»• biáº¿n cá»§a item dá»±a trÃªn dá»¯ liá»‡u test (hoáº·c train náº¿u cÃ³)"""
    print("ğŸ“Š Äang tÃ­nh toÃ¡n Ä‘á»™ phá»• biáº¿n (Most Popular)...")
    all_items = []
    for s in test_set:
        all_items.extend(s['input_items'])
    
    # Äáº¿m táº§n suáº¥t xuáº¥t hiá»‡n
    item_counts = Counter(all_items)
    return item_counts

# =============================================================================
# 4. MAIN PROGRAM
# =============================================================================
def main():
    print("\n" + "="*60)
    print("ğŸš€ BENCHMARK: SASREC vs RANDOM vs MOST POPULAR")
    print("="*60)

    # 1. Load Data
    try:
        run_id, model_path, test_set_path, item_map_path = fetch_artifacts_and_get_run_id()
    except Exception as e:
        print(f"âŒ {e}"); return

    with open(test_set_path, "rb") as f: test_set = pickle.load(f)
    
    # Load Vocab Size
    if item_map_path and os.path.exists(item_map_path):
        with open(item_map_path, "r") as f: vocab_size = len(json.load(f))
    else:
        all_items = [x for s in test_set for x in s['input_items']]
        vocab_size = max(all_items)

    # 2. Chuáº©n bá»‹ Baseline
    # TÃ­nh Popularity Map (Item ID -> Sá»‘ láº§n xuáº¥t hiá»‡n)
    pop_map = calculate_popularity_scores(test_set)

    # 3. Load Model SasRec
    print(f"ğŸ—ï¸ Loading SasRec Model...")
    model = tf.keras.models.load_model(model_path, custom_objects={'SasRec': SasRec}, compile=False)
    item_weights = model.item_embedding.embeddings 

    # 4. EVALUATION LOOP
    metrics = {
        "Random": {"hits": 0, "ndcg": 0},
        "MostPopular": {"hits": 0, "ndcg": 0},
        "SasRec": {"hits": 0, "ndcg": 0}
    }
    
    print(f"\nğŸ Äang cháº¡y Ä‘ua 3 thuáº­t toÃ¡n trÃªn {len(test_set)} users...")
    
    for sample in tqdm(test_set):
        seq_items = sample["input_items"]
        seq_cats = sample["input_cats"]
        target_item = sample["label"]

        # --- A. Common Setup (Negative Sampling) ---
        seen_items = set(seq_items)
        seen_items.add(target_item)
        
        # Táº¡o danh sÃ¡ch 100 á»©ng viÃªn (1 tháº­t + 99 giáº£)
        candidates = [target_item]
        while len(candidates) < NUM_NEG_TEST + 1:
            neg = np.random.randint(1, vocab_size + 1)
            if neg not in seen_items:
                candidates.append(neg)
        
        # --- B. CHáº¤M ÄIá»‚M Tá»ªNG THUáº¬T TOÃN ---
        
        # 1. RANDOM (GÃ¡n Ä‘iá»ƒm ngáº«u nhiÃªn)
        rand_scores = np.random.rand(len(candidates))
        
        # 2. MOST POPULAR (GÃ¡n Ä‘iá»ƒm báº±ng sá»‘ láº§n xuáº¥t hiá»‡n)
        # Náº¿u item chÆ°a tá»«ng tháº¥y thÃ¬ score = 0
        pop_scores = np.array([pop_map.get(i, 0) for i in candidates])
        # Cá»™ng thÃªm nhiá»…u cá»±c nhá» Ä‘á»ƒ phÃ¡ vá»¡ tháº¿ cÃ¢n báº±ng (break ties)
        pop_scores = pop_scores + np.random.uniform(0, 1e-6, size=len(pop_scores))

        # 3. SASREC (Deep Learning)
        # Preprocessing
        seq_i = list(seq_items)[-MAX_LEN:]
        seq_c = list(seq_cats)[-MAX_LEN:]
        valid_len = len(seq_i)
        in_i, mask = pad_sequence(seq_i, MAX_LEN)
        in_c, _ = pad_sequence(seq_c, MAX_LEN)
        
        outputs = model({
            "item_ids": np.expand_dims(in_i, 0), 
            "category_ids": np.expand_dims(in_c, 0), 
            "padding_mask": np.expand_dims(mask, 0)
        }, training=False)
        
        user_emb = outputs["item_sequence_embedding"][0][valid_len - 1]
        
        cand_tensor = tf.constant(candidates, dtype=tf.int32)
        cand_embs = tf.gather(item_weights, cand_tensor)
        sasrec_scores = tf.matmul(cand_embs, tf.expand_dims(user_emb, -1))
        sasrec_scores = tf.squeeze(sasrec_scores).numpy()

        # --- C. RANKING & METRICS ---
        # HÃ m tÃ­nh Rank chung cho cáº£ 3
        def calculate_rank(scores):
            # Äiá»ƒm cá»§a mÃ³n Ä‘á»“ tháº­t náº±m á»Ÿ index 0
            target_score = scores[0]
            # Rank = sá»‘ lÆ°á»£ng mÃ³n cÃ³ Ä‘iá»ƒm cao hÆ¡n mÃ³n tháº­t
            return np.sum(scores > target_score)

        # TÃ­nh rank cho tá»«ng thuáº­t toÃ¡n
        rank_rand = calculate_rank(rand_scores)
        rank_pop = calculate_rank(pop_scores)
        rank_sas = calculate_rank(sasrec_scores)

        # Cá»™ng Ä‘iá»ƒm
        for alg, r in zip(["Random", "MostPopular", "SasRec"], [rank_rand, rank_pop, rank_sas]):
            if r < 10:
                metrics[alg]["hits"] += 1
                metrics[alg]["ndcg"] += 1.0 / np.log2(r + 2)

    # 5. Tá»”NG Há»¢P Káº¾T QUáº¢
    final_results = {"count": len(test_set)}
    
    print("\n" + "=" * 60)
    print(f"ğŸ† Báº¢NG Xáº¾P Háº NG CUá»I CÃ™NG (Benchmark)")
    print("=" * 60)
    print(f"{'THUáº¬T TOÃN':<15} | {'HR@10':<10} | {'NDCG@10':<10} | {'NHáº¬N XÃ‰T'}")
    print("-" * 60)

    for alg in ["Random", "MostPopular", "SasRec"]:
        hr = metrics[alg]["hits"] / len(test_set)
        ndcg = metrics[alg]["ndcg"] / len(test_set)
        final_results[alg] = {"hr": hr, "ndcg": ndcg}
        
        comment = "Tá»‡ (ÄoÃ¡n mÃ²)" if alg == "Random" else ("KhÃ¡ (Theo Trend)" if alg == "MostPopular" else "Tá»T NHáº¤T ğŸš€")
        print(f"{alg:<15} | {hr:.4f}     | {ndcg:.4f}     | {comment}")

    print("=" * 60)

    # 6. LÆ¯U VÃ€O DB
    save_benchmark_to_db(final_results, run_id)

if __name__ == "__main__":
    main()