import os
import json
import boto3
from botocore.exceptions import NoCredentialsError

# ================== C·∫§U H√åNH ==================
MINIO_ENDPOINT = "http://minio:9000" 
ACCESS_KEY = "minioadmin"
SECRET_KEY = "minioadmin"
BUCKET_NAME = "datalake"

# ƒê∆∞·ªùng d·∫´n Local (N∆°i b·∫°n ƒëang c√≥ d·ªØ li·ªáu trong VS Code)
LOCAL_MODEL_REGISTRY = "data/model_registry" 

# ================== H√ÄM UPLOAD ƒê·ªÜ QUY ==================
def upload_folder_to_s3(s3_client, local_folder, s3_prefix):
    """
    Upload to√†n b·ªô th∆∞ m·ª•c local l√™n MinIO gi·ªØ nguy√™n c·∫•u tr√∫c
    """
    if not os.path.exists(local_folder):
        print(f"‚ö†Ô∏è Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i, b·ªè qua: {local_folder}")
        return

    print(f"üìÇ ƒêang qu√©t th∆∞ m·ª•c: {local_folder} ...")
    
    for root, dirs, files in os.walk(local_folder):
        for filename in files:
            # ƒê∆∞·ªùng d·∫´n file tr√™n m√°y local
            local_path = os.path.join(root, filename)
            
            # T√≠nh to√°n ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ƒë·ªÉ t·∫°o Key tr√™n S3
            relative_path = os.path.relpath(local_path, local_folder)
            s3_key = os.path.join(s3_prefix, relative_path).replace("\\", "/") # Fix l·ªói ƒë∆∞·ªùng d·∫´n Windows
            
            try:
                s3_client.upload_file(local_path, BUCKET_NAME, s3_key)
            except Exception as e:
                print(f"  ‚ùå L·ªói file {filename}: {e}")
    print(f"‚úÖ ƒê√£ upload xong folder v√†o: s3://{BUCKET_NAME}/{s3_prefix}")

# ================== H√ÄM PATCH CONFIG (M·ªöI B·ªî SUNG) ==================
def patch_model_config(s3_client):
    """
    T·∫£i file config v·ªÅ, s·ª≠a latest_model_path, r·ªìi upload l·∫°i
    """
    config_key = "model_registry/model_meta_config.json"
    local_temp_config = "temp_config.json"
    
    print("\n--- 5. C·∫¨P NH·∫¨T FILE CONFIG (AUTO-PATCH) ---")
    try:
        # 1. T·∫£i file config hi·ªán t·∫°i v·ªÅ (n·∫øu c√≥)
        try:
            s3_client.download_file(BUCKET_NAME, config_key, local_temp_config)
            with open(local_temp_config, 'r') as f:
                config = json.load(f)
        except:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y config tr√™n S3, t·∫°o m·ªõi.")
            config = {}

        # 2. C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n model g·ªëc
        target_path = f"s3://datalake/model_registry/sasrec_v1.keras"
        config["latest_model_path"] = target_path
        
        # 3. Ghi l·∫°i v√† Upload
        with open(local_temp_config, 'w') as f:
            json.dump(config, f, indent=4)
            
        s3_client.upload_file(local_temp_config, BUCKET_NAME, config_key)
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t 'latest_model_path' = {target_path}")
        
        # D·ªçn d·∫πp file t·∫°m
        if os.path.exists(local_temp_config):
            os.remove(local_temp_config)
            
    except Exception as e:
        print(f"‚ùå L·ªói khi patch config: {e}")

def main():
    # 1. Kh·ªüi t·∫°o k·∫øt n·ªëi
    s3 = boto3.client('s3',
                      endpoint_url=MINIO_ENDPOINT,
                      aws_access_key_id=ACCESS_KEY,
                      aws_secret_access_key=SECRET_KEY)
    
    print(f"üöÄ B·∫ÆT ƒê·∫¶U ƒê·ªíNG B·ªò D·ªÆ LI·ªÜU L√äN MINIO ({MINIO_ENDPOINT})...")

    # =========================================================
    # 2. UPLOAD C√ÅC FILE C·∫§U H√åNH & MAP (JSON/PKL)
    # =========================================================
    print("\n--- 1. UPLOAD METADATA & MAPS ---")
    files_to_upload = [
        "item_map.json", 
        "category_map.json", 
        "item_category.json",
        "model_meta_config.json", 
        "test_set.pkl",
        "sasrec_v1.keras",
        "sasrec_v2.keras"
    ]
    
    for fname in files_to_upload:
        local_path = os.path.join(LOCAL_MODEL_REGISTRY, fname)
        if os.path.exists(local_path):
            s3.upload_file(local_path, BUCKET_NAME, f"model_registry/{fname}")
            print(f"‚úÖ OK: {fname}")
        else:
            print(f"‚ö†Ô∏è Missing: {fname}")

    # =========================================================
    # 3. UPLOAD CHECKPOINT MODEL
    # =========================================================
    print("\n--- 2. UPLOAD MODEL CHECKPOINT ---")
    ckpt_source = os.path.join(LOCAL_MODEL_REGISTRY, "sasrec_v1.keras")
    ckpt_dest = "model_registry/checkpoints/sasrec_latest.keras" 
    
    if os.path.exists(ckpt_source):
        print(f"‚¨ÜÔ∏è Uploading: sasrec_v1.keras -> {ckpt_dest}")
        s3.upload_file(ckpt_source, BUCKET_NAME, ckpt_dest)
        print("‚úÖ Checkpoint Uploaded!")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y 'sasrec_v1.keras'.")

    # =========================================================
    # 4. UPLOAD D·ªÆ LI·ªÜU (PARQUET)
    # =========================================================
    print("\n--- 3. UPLOAD DATASET (OLD & NEW) ---")
    
    # upload_folder_to_s3(s3, 
    #                     os.path.join(LOCAL_MODEL_REGISTRY, "processed_parquet"), 
    #                     "processed_parquet")
    
    # upload_folder_to_s3(s3, 
    #                     os.path.join(LOCAL_MODEL_REGISTRY, "incremental_dec_2025"), 
    #                     "incremental_dec_2025")

    # =========================================================
    # 5. UPLOAD MODEL SERVING
    # =========================================================
    print("\n--- 4. UPLOAD MODEL SERVING (EXPORTED) ---")
    local_model_path = os.path.join(LOCAL_MODEL_REGISTRY, "1")
    
    if os.path.exists(local_model_path):
        # upload_folder_to_s3(s3, local_model_path, "models/sasrec/1")
        print("‚úÖ Serving Model Uploaded!")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y folder model '1'.")

    # =========================================================
    # 6. G·ªåI H√ÄM PATCH CONFIG
    # =========================================================
    patch_model_config(s3)

    print("\nüéâüéâüéâ HO√ÄN T·∫§T ƒê·ªíNG B·ªò!")

if __name__ == "__main__":
    main()