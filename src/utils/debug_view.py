import os
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

# Config
MINIO_ENDPOINT = "http://minio:9000"
ACCESS_KEY = "minioadmin"
SECRET_KEY = "minioadmin"
# ÄÆ°á»ng dáº«n gá»‘c
S3_INPUT = "s3a://datalake/topics/processed_clicks"

def main():
    spark = SparkSession.builder \
        .appName("Debug_View_Raw") \
        .config("spark.hadoop.fs.s3a.endpoint", MINIO_ENDPOINT) \
        .config("spark.hadoop.fs.s3a.access.key", ACCESS_KEY) \
        .config("spark.hadoop.fs.s3a.secret.key", SECRET_KEY) \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
        .getOrCreate()

    spark.sparkContext.setLogLevel("ERROR")
    print("ğŸ” Báº®T Äáº¦U DEBUG Dá»® LIá»†U...")

    try:
        # 1. Äá»c dá»¯ liá»‡u
        df = spark.read.option("basePath", S3_INPUT) \
                       .option("mergeSchema", "true") \
                       .option("recursiveFileLookup", "true") \
                       .parquet(S3_INPUT)
        
        # 2. In ra 20 dÃ²ng Ä‘áº§u tiÃªn (Raw Data)
        print("\n--- 1. MáºªU Dá»® LIá»†U THÃ” (TOP 20) ---")
        # Chá»‰ chá»n cÃ¡c cá»™t quan trá»ng Ä‘á»ƒ hiá»ƒn thá»‹ cho gá»n
        df.select("user_id", "item_id", "timestamp", "item_idx").show(20, truncate=False)

        # 3. Kiá»ƒm tra User ID
        print("\n--- 2. THá»NG KÃŠ USER ---")
        user_counts = df.groupBy("user_id").count()
        user_counts.show(10, truncate=False)
        
        total_rows = df.count()
        null_users = df.filter(F.col("user_id").isNull()).count()
        print(f"ğŸ“Š Tá»•ng sá»‘ dÃ²ng: {total_rows}")
        print(f"âŒ Sá»‘ dÃ²ng bá»‹ NULL User ID: {null_users}")

        if total_rows > 0 and null_users == total_rows:
            print("ğŸš¨ Lá»–I Lá»šN: ToÃ n bá»™ User ID Ä‘á»u bá»‹ Null/Rá»—ng! Kiá»ƒm tra láº¡i nguá»“n Kafka/Avro.")

    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

    spark.stop()

if __name__ == "__main__":
    main()