# import time
# import json
# import random
# import os
# import uuid
# from datetime import datetime

# # ThÆ° viá»‡n Confluent Kafka há»— trá»£ Avro
# from confluent_kafka import SerializingProducer
# from confluent_kafka.serialization import StringSerializer
# from confluent_kafka.schema_registry import SchemaRegistryClient
# from confluent_kafka.schema_registry.avro import AvroSerializer

# # ==========================================
# # Cáº¤U HÃŒNH (CONFIG)
# # ==========================================
# KAFKA_BOOTSTRAP = os.getenv('KAFKA_BOOTSTRAP', 'localhost:9092')
# SCHEMA_REGISTRY_URL = os.getenv('SCHEMA_REGISTRY_URL', 'http://localhost:9081')
# TOPIC = 'raw_clicks_avro'  # TÃªn topic cho data Avro

# # Path load dá»¯ liá»‡u giáº£ láº­p
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# PROJECT_ROOT = os.path.dirname(os.path.dirname(BASE_DIR))
# VALID_USERS_PATH = os.path.join(PROJECT_ROOT, 'src/simulation/users.json')
# ITEM_MAP_PATH = os.path.join(PROJECT_ROOT, 'data/model_registry/item_map.json')

# # ==========================================
# # Äá»ŠNH NGHÄ¨A AVRO SCHEMA
# # ==========================================
# KEY_SCHEMA_STR = """
# {
#   "type": "string"
# }
# """

# VALUE_SCHEMA_STR = """
# {
#   "namespace": "ecommerce.tracking",
#   "type": "record",
#   "name": "UserClick",
#   "fields": [
#     {"name": "event_id", "type": "string"},
#     {"name": "session_id", "type": "string"},
#     {"name": "user_id", "type": "string"},
#     {"name": "item_id", "type": "string"},
#     {"name": "event_type", "type": "string"},
#     {"name": "rating_original", "type": "float"},
#     {"name": "timestamp", "type": "string"},
#     {"name": "context", "type": {
#         "type": "record",
#         "name": "ContextData",
#         "fields": [
#             {"name": "device", "type": "string"},
#             {"name": "location", "type": "string"},
#             {"name": "ip", "type": "string"}
#         ]
#     }}
#   ]
# }
# """

# # ==========================================
# # LOAD DATA HELPER
# # ==========================================
# def load_valid_data():
#     print(f"ğŸ“‚ Äang Ä‘á»c User tá»«: {VALID_USERS_PATH}")
    
#     if not os.path.exists(VALID_USERS_PATH):
#         print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y valid_users.json.")
#         exit()

#     with open(VALID_USERS_PATH, 'r') as f:
#         users = json.load(f)

#     with open(ITEM_MAP_PATH, 'r') as f:
#         item_map = json.load(f)
#         # item_map format: {"ItemID_Str": Index_Int} -> Láº¥y keys lÃ  ItemID
#         items = list(item_map.values())

#     print(f"âœ… ÄÃ£ load: {len(users)} Users vÃ  {len(items)} Items.")
#     return users, items

# # ==========================================
# # CALLBACK FUNCTION
# # ==========================================
# def delivery_report(err, msg):
#     """HÃ m nÃ y Ä‘Æ°á»£c gá»i khi Kafka xÃ¡c nháº­n Ä‘Ã£ nháº­n tin nháº¯n"""
#     if err is not None:
#         print(f"âŒ Delivery failed for User record {msg.key()}: {err}")
#     # else:
#     #     print(f"âœ… Record {msg.key()} produced to {msg.topic()} [{msg.partition()}]")

# # ==========================================
# # MAIN LOOP
# # ==========================================
# def main():
#     # 1. Load Data
#     valid_users, valid_items = load_valid_data()
    
#     # 2. Setup Schema Registry Client
#     schema_registry_conf = {'url': SCHEMA_REGISTRY_URL}
#     schema_registry_client = SchemaRegistryClient(schema_registry_conf)

#     # 3. Setup Avro Serializer
#     avro_serializer = AvroSerializer(
#         schema_registry_client,
#         VALUE_SCHEMA_STR
#     )

#     # 4. Setup Producer Configuration
#     producer_conf = {
#         'bootstrap.servers': KAFKA_BOOTSTRAP,
#         'key.serializer': StringSerializer('utf_8'),
#         'value.serializer': avro_serializer
#     }

#     producer = SerializingProducer(producer_conf)

#     print(f"ğŸš€ Báº¯t Ä‘áº§u báº¯n Avro vÃ o topic: {TOPIC}...")

#     try:
#         while True:
#             # --- Táº¡o dá»¯ liá»‡u giáº£ láº­p ---
#             user_id = str(random.choice(valid_users))
#             item_id = str(random.choice(valid_items))
#             print(item_id)
            
#             event_type = random.choice(['click', 'view', 'add_to_cart', 'purchase'])
#             device = random.choice(['mobile', 'desktop', 'tablet'])
#             location = random.choice(['Hanoi', 'HCM', 'Danang', 'Cantho'])
            
#             # Táº¡o Object Python khá»›p hoÃ n toÃ n vá»›i Schema Avro
#             value_obj = {
#                 "event_id": str(uuid.uuid4()),
#                 "session_id": str(uuid.uuid4()),
#                 "user_id": user_id,
#                 "item_id": item_id,
#                 "event_type": event_type,
#                 "rating_original": round(random.uniform(1.0, 5.0), 1),
#                 "timestamp": datetime.now().isoformat(),
#                 # Nested Record (Context)
#                 "context": {
#                     "device": device,
#                     "location": location,
#                     "ip": f"192.168.1.{random.randint(1, 255)}"
#                 }
#             }

#             print(f"ğŸ“¤ Sending Avro: User={user_id} -> Item={item_id} | Type={event_type}")

#             # --- Gá»­i tin nháº¯n ---
#             # Producer nÃ y sáº½ tá»± Ä‘á»™ng:
#             # 1. ÄÄƒng kÃ½ Schema lÃªn Registry (náº¿u chÆ°a cÃ³).
#             # 2. Láº¥y Schema ID.
#             # 3. ChÃ¨n 5-byte header + data binary.
#             producer.produce(
#                 topic=TOPIC,
#                 key=user_id, # DÃ¹ng UserID lÃ m Key Ä‘á»ƒ partition Ä‘Ãºng
#                 value=value_obj,
#                 on_delivery=delivery_report
#             )

#             # Poll Ä‘á»ƒ trigger callback delivery_report
#             producer.poll(0)
            
#             time.sleep(0.002) # Báº¯n 1 tin/giÃ¢y

#     except KeyboardInterrupt:
#         print("\nğŸ›‘ Dá»«ng simulation.")
#     except Exception as e:
#         print(f"âŒ Lá»—i Producer: {e}")
#     finally:
#         print("â³ Äang flush dá»¯ liá»‡u cÃ²n sÃ³t láº¡i...")
#         producer.flush()

# if __name__ == "__main__":
#     main()

import time
import json
import random
import os
import uuid
import argparse
from datetime import datetime, timedelta

# ThÆ° viá»‡n Confluent Kafka
from confluent_kafka import SerializingProducer
from confluent_kafka.serialization import StringSerializer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroSerializer

# ==========================================
# Cáº¤U HÃŒNH (CONFIG)
# ==========================================
KAFKA_BOOTSTRAP = os.getenv('KAFKA_BOOTSTRAP', 'localhost:9092')
SCHEMA_REGISTRY_URL = os.getenv('SCHEMA_REGISTRY_URL', 'http://localhost:9081')
TOPIC = 'raw_clicks_avro'

# Path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(BASE_DIR))
VALID_USERS_PATH = os.path.join(PROJECT_ROOT, 'src/simulation/users.json')
ITEM_MAP_PATH = os.path.join(PROJECT_ROOT, 'data/model_registry/item_map.json')

# ==========================================
# SCHEMA (Giá»¯ nguyÃªn)
# ==========================================
VALUE_SCHEMA_STR = """
{
  "namespace": "ecommerce.tracking",
  "type": "record",
  "name": "UserClick",
  "fields": [
    {"name": "event_id", "type": "string"},
    {"name": "session_id", "type": "string"},
    {"name": "user_id", "type": "string"},
    {"name": "item_id", "type": "string"},
    {"name": "event_type", "type": "string"},
    {"name": "rating_original", "type": "float"},
    {"name": "timestamp", "type": "string"},
    {"name": "context", "type": {
        "type": "record",
        "name": "ContextData",
        "fields": [
            {"name": "device", "type": "string"},
            {"name": "location", "type": "string"},
            {"name": "ip", "type": "string"}
        ]
    }}
  ]
}
"""

def load_valid_data():
    if not os.path.exists(VALID_USERS_PATH):
        # Fallback náº¿u chÆ°a cÃ³ file user
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file users.json, táº¡o user giáº£ láº­p táº¡m thá»i.")
        return [f"User_{i}" for i in range(100)], [f"Item_{i}" for i in range(1000)]

    with open(VALID_USERS_PATH, 'r') as f:
        users = json.load(f)
    with open(ITEM_MAP_PATH, 'r') as f:
        item_map = json.load(f)
        # Láº¥y Key (ASIN/ID gá»‘c) thay vÃ¬ Value
        items = list(item_map.keys()) 
    return users, items

def delivery_report(err, msg):
    if err is not None:
        print(f"âŒ Message delivery failed: {err}")

# ==========================================
# MAIN SIMULATION LOGIC
# ==========================================
def main():
    # 1. Cáº¥u hÃ¬nh tham sá»‘ cháº¡y
    parser = argparse.ArgumentParser()
    parser.add_argument("--days", type=int, default=14, help="Sá»‘ ngÃ y muá»‘n giáº£ láº­p (VD: 14 ngÃ y)")
    parser.add_argument("--msgs-per-day", type=int, default=2000, help="Sá»‘ message má»—i ngÃ y")
    args = parser.parse_args()

    # 2. Setup Kafka
    users, items = load_valid_data()
    schema_registry_client = SchemaRegistryClient({'url': SCHEMA_REGISTRY_URL})
    avro_serializer = AvroSerializer(schema_registry_client, VALUE_SCHEMA_STR)
    
    producer_conf = {
        'bootstrap.servers': KAFKA_BOOTSTRAP,
        'key.serializer': StringSerializer('utf_8'),
        'value.serializer': avro_serializer,
        'queue.buffering.max.messages': 50000 # TÄƒng buffer Ä‘á»ƒ báº¯n nhanh hÆ¡n
    }
    producer = SerializingProducer(producer_conf)

    # 3. TÃ­nh toÃ¡n thá»i gian báº¯t Ä‘áº§u (LÃ¹i láº¡i N ngÃ y so vá»›i hiá»‡n táº¡i)
    # VÃ­ dá»¥: HÃ´m nay 23/12, lÃ¹i 14 ngÃ y -> Báº¯t Ä‘áº§u tá»« 09/12
    start_date = datetime.now() - timedelta(days=args.days)
    
    print(f"ğŸš€ Báº®T Äáº¦U GIáº¢ Láº¬P: {args.days} ngÃ y | {args.msgs_per_day} msg/ngÃ y")
    print(f"ğŸ“… Thá»i gian dá»¯ liá»‡u (Event Time): Tá»« {start_date.strftime('%Y-%m-%d')} Ä‘áº¿n {datetime.now().strftime('%Y-%m-%d')}")
    print("-" * 50)

    total_sent = 0

    try:
        # --- VÃ’NG Láº¶P NGÃ€Y (Tá»« ngÃ y xÆ°a -> HÃ´m nay) ---
        for day_offset in range(args.days):
            current_day = start_date + timedelta(days=day_offset)
            print(f"ğŸ“… Äang sinh dá»¯ liá»‡u cho ngÃ y: {current_day.strftime('%Y-%m-%d')} ...")

            # --- VÃ’NG Láº¶P MESSAGE TRONG NGÃ€Y ---
            for _ in range(args.msgs_per_day):
                # Random thá»i gian trong vÃ²ng 24h cá»§a ngÃ y hÃ´m Ä‘Ã³
                random_second = random.randint(0, 86399)
                event_time = current_day.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(seconds=random_second)

                user_id = str(random.choice(users))
                item_id = str(random.choice(items))
                event_type = random.choice(['click', 'click', 'click', 'view', 'purchase']) # Æ¯u tiÃªn click nhiá»u hÆ¡n

                value_obj = {
                    "event_id": str(uuid.uuid4()),
                    "session_id": str(uuid.uuid4()),
                    "user_id": user_id,
                    "item_id": item_id,
                    "event_type": event_type,
                    "rating_original": round(random.uniform(1.0, 5.0), 1),
                    "timestamp": event_time.isoformat(), # <--- DÃ¹ng thá»i gian giáº£ láº­p
                    "context": {
                        "device": random.choice(['mobile', 'desktop']),
                        "location": random.choice(['Hanoi', 'HCM']),
                        "ip": "127.0.0.1"
                    }
                }

                producer.produce(
                    topic=TOPIC,
                    key=user_id,
                    value=value_obj,
                    on_delivery=delivery_report
                )
                
                total_sent += 1
                
                # Cá»© 1000 tin thÃ¬ poll má»™t láº§n Ä‘á»ƒ giáº£i phÃ³ng bá»™ nhá»› (nhanh hÆ¡n sleep tá»«ng tin)
                if total_sent % 1000 == 0:
                    producer.poll(0)
            
            # Flush nháº¹ sau má»—i ngÃ y Ä‘á»ƒ Ä‘áº£m báº£o data vÃ o Kafka theo thá»© tá»± tÆ°Æ¡ng Ä‘á»‘i
            producer.flush()
            print(f"   âœ… Xong ngÃ y {current_day.strftime('%Y-%m-%d')} ({args.msgs_per_day} msgs)")

    except KeyboardInterrupt:
        print("\nğŸ›‘ Dá»«ng simulation.")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
    finally:
        producer.flush()
        print(f"\nğŸ‰ HOÃ€N Táº¤T! Tá»•ng cá»™ng {total_sent} báº£n tin Ä‘Ã£ Ä‘Æ°á»£c gá»­i vÃ o Kafka.")

if __name__ == "__main__":
    main()