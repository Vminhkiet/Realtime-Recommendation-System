version: '3.9'

services:
  # =========================================
  # 1. Háº  Táº¦NG MESSAGING & GOVERNANCE
  # =========================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - spark-kafka-net

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - spark-kafka-net

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "9081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - spark-kafka-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    depends_on:
      - kafka
      - schema-registry
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    networks:
      - spark-kafka-net

  # =========================================
  # 2. Háº  Táº¦NG INTEGRATION (KAFKA CONNECT - CUSTOM BUILD)
  # =========================================
  kafka-connect:
    build:
      context: ./infra/kafka-connector
      dockerfile: Dockerfile
    container_name: kafka-connect
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_GROUP_ID: compose-connect-group

      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status

      # ğŸ”¥ Báº®T BUá»˜C THÃŠM 3 DÃ’NG NÃ€Y
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      # Avro converter
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"

      CONNECT_REST_PORT: 8083

      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    networks:
      - spark-kafka-net

  # =========================================
  # 3. Háº  Táº¦NG LÆ¯U TRá»® (STORAGE LAYER)
  # =========================================
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis_data:/data
    networks:
      - spark-kafka-net

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./data/lake:/data
    networks:
      - spark-kafka-net

  mongo:
    image: mongo:4.4.6
    container_name: mongo
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongo_data:/data/db
    networks:
      - spark-kafka-net

  timescaledb:
    image: timescale/timescaledb:latest-pg14
    container_name: timescaledb
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ecommerce_logs
    ports:
      - "5432:5432"
    volumes:
      - ./data/timescale_data:/var/lib/postgresql/data
    networks:
      - spark-kafka-net

  # =========================================
  # 4. SPARK CLUSTER
  # =========================================
  spark-master:
    build: ./base
    container_name: spark-master
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - ./src:/home/spark/work/src
      - ./data:/home/spark/work/data
    networks:
      - spark-kafka-net

  spark-worker:
    build: ./base
    user: root
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
    volumes:
      - ./src:/home/spark/work/src
      - ./data:/home/spark/work/data
    networks:
      - spark-kafka-net

  jupyter-spark:
    build: ./base
    container_name: jupyter-spark
    user: root
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes:
      - ./notebooks:/home/spark/work/notebooks
      - ./src:/home/spark/work/src
      - ./data:/home/spark/work/data
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      - spark-kafka-net

  # =========================================
  # 5. SERVING LAYER
  # =========================================
  dashboard:
    build: ./base  # (Hoáº·c ./infra/spark-base tÃ¹y vÃ o thÆ° má»¥c báº¡n táº¡o)
    container_name: dashboard
    user: root
    ports:
      - "8501:8501"
    volumes:
      - ./src:/home/spark/work/src
      - ./data:/home/spark/work/data
    working_dir: /home/spark/work
    environment:
      - KAFKA_SERVER=kafka:29092
      - MONGO_URI=mongodb://mongo:27017/
      - TIMESCALE_URI=postgresql://postgres:password@timescaledb:5432/ecommerce_logs
    # --- Sá»¬A DÃ’NG NÃ€Y ---
    command: >
      bash -c "pip install streamlit pandas matplotlib && 
      streamlit run src/dashboard/app.py --server.port 8501 --server.address 0.0.0.0"
    networks:
      - spark-kafka-net

networks:
  spark-kafka-net:
    driver: bridge
